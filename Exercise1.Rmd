---
title: "Timothy Gan, Randal Donaldson"
output: github_document
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
#library(mosaic)
ABIA = read.csv("data/ABIA.csv")
creatinine = read.csv("data/creatinine.csv")
milk = read.csv("data/milk.csv")
lm1 = lm(creatclear ~ age, data = creatinine)
greenbuildings = read.csv("data/greenbuildings.csv")
```


## ABIA:

What day is the best day to avoid departure delays?

```{r, ABIA, message=TRUE, warning=TRUE, echo=FALSE}
ABIA$DayOfWeek[ABIA$DayOfWeek == 1] <- 'Monday'
ABIA$DayOfWeek[ABIA$DayOfWeek == 2] <- 'Tuesday'
ABIA$DayOfWeek[ABIA$DayOfWeek == 3] <- 'Wednesday'
ABIA$DayOfWeek[ABIA$DayOfWeek == 4] <- 'Thursday'
ABIA$DayOfWeek[ABIA$DayOfWeek == 5] <- 'Friday'
ABIA$DayOfWeek[ABIA$DayOfWeek == 6] <- 'Saturday'
ABIA$DayOfWeek[ABIA$DayOfWeek == 7] <- 'Sunday'
ABIA$DayOfWeek <- factor(ABIA$DayOfWeek,levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
security_summ = ABIA %>%
  group_by(DayOfWeek)  %>%  # group the data points by model name
  summarize(DepartureDelay.mean = mean(DepDelay, na.rm=TRUE))  # calculate a mean for each model

ggplot(security_summ, aes(x=DayOfWeek, y=DepartureDelay.mean)) + 
  geom_bar(stat='identity') +  labs(title= "Departure Delays",
                      y="Delay in minutes", x = "Day Of Week")
```


## Creatinine:

Scatter plot of age vs creatinine clearance rate

```{r, creatinine1, echo=FALSE}
plot(creatclear ~ age, data = creatinine, 
   xlab="Age (years)", ylab="Creatclear (ml/min)")
title(main="Creatinine clearance rate vs Age")
```

We found a first order polynomial to work fine, as a second order polynomial looked pretty much like a straight line. A first order regression gives us the equation:

creatclear = (age * -.619) + 147.81

```{r, creatinine2, echo=FALSE}
plot(creatclear ~ age, data = creatinine, 
   xlab="Age (years)", ylab="Creatclear (ml/min)")
title(main="Creatinine clearance rate vs Age")
abline(147.81, -0.619)
```

We run the linear equation in R with $x = 55$ to predict the creatclear of a 55 year old:

```{r, creatinine3}
coef(lm1)[1] + 55*coef(lm1)[2]
``` 

According to our linear regression, creatinine clearance decreases at a rate of .619 mL/minute per year.

```{r, creatinine4, echo=FALSE}
plot(creatclear ~ age, data = creatinine, 
   xlab="Age (years)", ylab="Creatclear (ml/min)")
title(main="Creatinine clearance rate vs Age")
abline(147.81, -0.619)
points(40, y=135, col='blue', pch=19)
points(60, y=112, col='green', pch=19)
```

The blue point represents the 40 year old, and the green point represents the 60 year old. As seen, the difference between the 40 year old's creatinine clearance and the predicted clearance for 40 year olds is much higher than the difference between the 60 year old's creatinine clearance and the predicted clearance for 60 year olds.

## Green Buildings:

The Excel Guru failed to consider that green buildings may be concentrated more in areas of lower or higher than average rent. 

```{r, diff, echo=FALSE}
greenbuildings$green_rating[greenbuildings$green_rating == 1] <- 'Green'
greenbuildings$green_rating[greenbuildings$green_rating == 0] <- 'Normal'
greenbuildings$rentAboveAverage = greenbuildings$Rent - greenbuildings$cluster_rent
above_summ = greenbuildings %>%
  group_by(green_rating)  %>%  # group the data points by model name
  summarize(above.mean = mean(rentAboveAverage))  # calculate a mean for each model

ggplot(above_summ, aes(x=green_rating, y=above.mean, fill = green_rating)) + 
  geom_bar(stat='identity') + labs(title= "",
                      y="Average Rent above Cluster (Dollars/sq ft.)", x = "Building type", fill = "Building type")
```

When taking in to account difference between rent and average rent in the surrounding area, the difference between greenbuildings and non green buildings becomes smaller: from around 2.7 to 2.3-2.4 dollars per square foot.

When only comparing buildings that are 15 stories the difference between green and non green becomes even smaller:


```{r, diff_15_story, echo=FALSE}
greenbuildings$green_rating[greenbuildings$green_rating == 1] <- 'Green'
greenbuildings$green_rating[greenbuildings$green_rating == 0] <- 'Normal'
greenbuildings$rentAboveAverage = greenbuildings$Rent - greenbuildings$cluster_rent
gb = subset(greenbuildings, stories == 15)
above_summ = gb %>%
  group_by(green_rating)  %>%  # group the data points by model name
  summarize(above.mean = mean(rentAboveAverage))  # calculate a mean for each model

ggplot(above_summ, aes(x=green_rating, y=above.mean, fill = green_rating)) + 
  geom_bar(stat='identity') + labs(title= "",
                      y="Average Rent above Cluster (Dollars/sq ft.)", x = "Building type", fill = "Building type")
```

The guru also failed to consider the difference in the types of green certifications:


```{r, type_comparison, echo=FALSE}
gb = greenbuildings
gb$green_rating[gb$LEED == 1] <- 'LEED'
gb$green_rating[gb$Energystar == 1] <- 'EnergyStar'
gb$green_rating[gb$green_rating == 0] <- 'Normal'
gb$rentAboveAverage = gb$Rent - gb$cluster_rent

above_summ = gb %>%
  group_by(green_rating)  %>%  # group the data points by model name
  summarize(above.mean = mean(rentAboveAverage))  # calculate a mean for each model

ggplot(above_summ, aes(x=green_rating, y=above.mean, fill = green_rating)) + 
  geom_bar(stat='identity') + labs(title= "",
                      y="Average Rent above Cluster (Dollars/sq ft.)", x = "Building type", fill = "Building type")
```

Assuming the costs to obtain LEED and EnergyStar certifications are similar, it is clear that LEED is the way to go.

It also stands to reason that green buildings are going to be much newer than non green buildings on average, and it would also stand to reason that newer buildings would have higher rent in general than older buildings regardless of green status


```{r, age_rent, echo=FALSE}
gb = subset(greenbuildings, renovated == 0)
gb$rentAboveAverage = gb$Rent - gb$cluster_rent
age_summ = gb %>%
  group_by(age) %>%
    summarize(above_mean = mean(rentAboveAverage))
ggplot(age_summ, aes(x=age, y=above_mean)) +
  geom_point(stat='identity') + 
  geom_smooth(method='lm', formula= y~x) + labs(title= "Age vs Rent in buildings without renovations",
                      y="Rent (Dollars/sq ft.)", x = "Age")

```

Seen here, there is a slight negative correlation between age and rent when buildings that have seen significant renovations are removed.


```{r, age_green, echo=FALSE}
greenbuildings$green_rating[greenbuildings$green_rating == 1] <- 'Green'
greenbuildings$green_rating[greenbuildings$green_rating == 0] <- 'Normal'
ggplot(data=greenbuildings) + 
  geom_boxplot(mapping=aes(x=green_rating, y=age, fill = green_rating)) + labs(title= "Average age for Building types in years",
                      y="Age (years)", x = "Building type", fill = "Building type")
```

As you can see, the vast majority of green buildings are 30 years or younger, which would skew the average rent that the guru used to make his calculations.

### Conclusion
If we use the same logic as the excel guru, but with the difference in rent of just 15 story buildings (2 dollars per square foot) we still find that the costs of green renovations should be recouped in about 10 years as opposed to 7.7, and likely even quicker if the new building receives a LEED certification. Therefore, his overall assessment that a green building would be profitable long term is probably correct, but his method of determining this has some faults.


## Milk:
As shown in class, N = (P - C) * Q where N is net profit, P is price, C is cost, and Q is quantity.

As for expressing Q in terms of P, we use the microeconomics equation that uses power laws to represent changes in consumer demand as a function of price: Q = KP<sup>PED</sup> where K is a constant and PED is price elasticity of demand.

We can combine these equations to yield N = (P * C) * KP<sup>PED</sup>

In order to solve for all the constants, we can take the log of the second equation, and use a linear regression to get those constants.

```{r, milk1}
lm2 = lm(log(sales) ~ log(price), data = milk)
coef(lm2)
```

PED is just going to be -1.618578, but the constant K is ***e***<sup>4.720604</sup> which happens to be 112.236022757. Given that cost is 1, we can now find the optimal price for the most profit through a few different ways. One is taking the derivative of the profit equation and setting the derivative to 0. From there, we check the points where the derivative is equal to 0 and find the maximum. We could also plot it in R and eyeball it and zoom closer and closer to the maximum. R also provides a really neat function to optimize an equation given a certain domain. The third option is demonstrated below.

```{r, milk2}
cost = 1
curve((x - cost)*112.236022757*x^(-1.618578), from=1, to=9) # 1 dollar to 9 dollars
title(main="Optimizing Milk price for profit", 
   xlab="Price to sell milk (dollars)", ylab="Profit (dollars)")
net <- function(x) { (x - cost)*112.236022757*x^(-1.618578)}
optimize(net, interval=c(1, 9), maximum=TRUE)
points(2.616605, y=38.24674, pch=19, col="blue")
```

The optimal price is $2.616605, and the max profit is $38.24674 given the cost of milk is $1. To calculate p given a certain c, just set the variable cost to whatever the cost of milk is.